<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Qihong Lu's Page</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">

  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Qihong Lu</h1>
        <p></p>
        
                
        <p class="view"> <a href="index.html">Home</a></p>
        <p class="view">Research Projects</p>        
        <p class="view"> <a href="academicCV.html">Academic CV</a></p>
        
        <p class="view">
        <a href="https://github.com/QihongL"> <img src="myImages/logo/github.png" alt="myGithub" style="width:40px;height:40px;"></a>
        <a href="mailto:qihong.lu@wisc.edu" target="_top"><img src="myImages/logo/email.png" alt="myEmail" style="width:40px;height:40px;"></a>
        </p>
        
        <p class="view">
        <a href="https://www.linkedin.com/in/qihong"> <img src="myImages/logo/linkedin.png" alt="myLinkedin" style="width:40px;height:40px;"></a>
        <a href="https://www.facebook.com/qihong.lu.9"> <img src="myImages/logo/facebook.png" alt="myFacebook" style="width:40px;height:40px;"></a>        
        </p>

      </header>
      <section>
        <h3>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Here're some selected research projects!</h3>

<h3><p> <strong>1. A recurrent neural network for human object recognition</strong></p> </h3>
<p style="width: 500px;">
<img src="/myImages/research/pdp_cat_demo.png">
</p> 
<p> This is a computational model for the temporal dynamics of human object recognition. Ultra-rapid categorization (<a href = "http://www.mitpressjournals.org/doi/abs/10.1162/jocn_a_00701#.V6ENc5MrJgo">Wu, et al., 2015</a>) has been considered as evidence for a feed-forward view of visual recognition (<a href = "http://www.pnas.org/content/104/15/6424.full">Serre, Oliva & Poggio, 2007</a>). Here, we show that an interactive model can be consistent with this result, and it can also explain many other behavioral and neural data. 
</p>
---
<p>
<b>Lu, Q.</b>, & Rogers, T. T. (2016). An interactive model accounts for both ultra-rapid superordinate classification and basic-level advantage in object recognition. 
<i>
Poster presented at the 38th Annual Meeting of the 
<a href = "http://cognitivesciencesociety.org/index.html"> Cognitive Science Society </a>
, Philadelphia, PA. 
</i>
[
<a href = "myDocs/cogsci2016_poster.pdf">Poster </a> , 
<a href = "https://github.com/QihongL/categorization_PDP"> Code </a> 
]
</p>

<br><br><br>



<h3><p> <strong>2. A reinforcement learning network for "counting"</strong></p></h3>
<p style="width: 400px;">
<img src="/myImages/research/countModel_envir.png">
</p> 

<p>Counting skill is a foundation for more sophisticated math concepts, and it takes children several years to learn to do it well. To understand this learning process, we explored how social feedback helps an artificial agent to learn a counting-related task. This modeling framework is inspired by the Deep-Q network (<a href = "http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html">Mnih, et al., 2015</a>). 

Currently, we are trying to augment this model with hard attention (<a href = "http://arxiv.org/abs/1406.6247">Mnih et al., 2014</a>).
</p>

---
<p>
<b>Lu, Q.</b>, & McClelland, J.L. (2016). Teaching a neural network to count: reinforcement learning with “social scaffolding”. 
<i>
Poster presented at the 15th
<a href = "http://www.cs.bham.ac.uk/~jxb/NCPW.html">  Neural Computation and Psychology Workshop </a>
, Philadelphia, PA. 
</i>
[
<a href = "myDocs/ncpw16_poster.pdf">Poster </a> , 
<a href = "https://github.com/QihongL/mathCognition_PDP_RL"> Code </a> 
]
</p>

<br><br><br>




<h3><p> <strong>3. Discover distributed representation via fMRI decoding</strong></p></h3>

<p style="width: 400px;">
<img src="/myImages/research/ilassoResults.png">
</p> 

<p>We investigated how faces, places and objects are represented in the human brain, with a novel multi-voxel pattern analysis (MVPA) method: whole-brain iterative logistic Lasso. Different from some conventional findings (<a href = "http://www.jneurosci.org/content/17/11/4302.full">Kanwisher, McDermott, and Chun, 1997</a>), we found that the neural representation of faces is highly distributed across the entire brain. </p>

---
<p>
Cox, C. R., <b>Lu, Q.</b>, & Rogers, T. T. (2015). Iterative Lasso: An even-handed approach to whole brain multivariate pattern analysis. 
<i>
Poster presented at the 22nd
<a href = "https://www.cogneurosociety.org/"> Cognitive Neuroscience Society </a> 
annual conference, San Francisco, CA.
</i>
[
<a href = "myDocs/cox_lu_rogers_CNS2015.pdf">Poster </a>
]
</p>




      </section>
      <footer>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
