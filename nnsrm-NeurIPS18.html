<!doctype html>
<html>

<!-- browser tab head  -->
<head>

<style>
* {
    box-sizing: border-box;
}

.column {
    float: left;
    width: 50%;
    padding: 0px;
}

/* Clearfix (clear floats) */
.row::after {
    content: "";
    clear: both;
    display: table;
}

/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
    .column {
        width: 100%;
    }
}
</style>


    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Qihong Lu | Research</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
    <link rel="shortcut icon" href="https://psych.princeton.edu/sites/psychology/themes/psychology/favicon.ico" type="image/vnd.microsoft.icon" />

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-83024954-2', 'auto');
      ga('send', 'pageview');
    </script>
</head>

<!-- the main body  -->

<body>
<div class="wrapper">

<!-- the left column  -->

<header>
    <h1>Qihong Lu</h1>
    <br>

    <p class="view"><h4><a href="index.html">Home</a></h4></p>
    <p class="view"><a href="research.html"><h4>Research</h4></a></p>
    <p class="view"><h4><a href="teaching.html">Teaching</a></h4></p>
    <p class="view"><a href="resources.html"><h4>Resources</h4></a></p>
    <p class="view"><a href="contact.html"><h4>Contact</h4></a></p>
    <br><br>

    <p class="view">
    <a href="https://scholar.google.com/citations?user=b9D0RmMAAAAJ&hl=en&oi=ao">
    <img src="imgs/logo/google-scholar.png" alt="google scholar" width=40px></a>
    <a href="https://twitter.com/Qihong_Lu">
    <img src="imgs/logo/twitter_r.png" alt="twitter" width=40px></a>
    </p>

    <p class="view">
    <a href="https://github.com/QihongL">
    <img src="imgs/logo/github.svg" alt="github" width=40px></a>
    <a href="mailto:qlu@princeton.edu" target="_top">
    <img src="imgs/logo/email.png" alt="email" width=40px></a>
    </p>
</header>

<!-- the END of left column  -->

<!-- the right column  -->

<section>

<h3>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>
</h3>

<p>
<h3><strong>Demo: rigid-body transformations can align hidden representational spaces across neural networks</strong></h3>
&emsp;
<a href="https://qihongl.github.io/docs/NIPS18_poster_NNSRM.pdf">poster</a>,
<a href="https://arxiv.org/abs/1811.11684">paper</a>,
<a href="https://github.com/qihongl/nnsrm-neurips18">code</a>,
<a href="https://colab.research.google.com/github/qihongl/demo-nnalign/blob/master/demo-nnalign.ipynb">tutorial on google colab</a>, 
<a href="https://qihongl.github.io/nnsrm-NeurIPS18.html">some animations</a>
<br>

</p>




When many instantiations of the same neural network architecture are trained on the same dataset, these networks tend to approximate the same mathematical mapping with very different weight configurations. What's the connection across these learned neural network solutions? In our recent work, we found the learned hidden representations across neural networks can be related by orthogonal transformations, which can be viewed as some rigid-body transformations.

<br>
<br>
Here we visualize the neural dynamics when all networks are viewing the same sequence of images (2000 images from CIFAR100 test set).
<br>
- All networks are trained on the same training set.
<br>
- Each line is a different neural network instance.
<br>
- We aligned these networks with the shared response model.
<br>
-<b> Caveat</b>: These results are three-dimensional PCA projections of some high dimensional neural dynamics (dim = # hidden units), so they should be interpreted carefully.

<br>
<br>
The animations below shows the neural dynamics of 5 conv nets (the last hidden layer) before alignment (Fig 1A). vs. after alignment (Fig 1B). High degree of alignment would suggest the geometry of the hidden representation across networks are highly similar. Namely, different neural networks learn different orthogonal transformations of the same representational structure.
<br>

<div class="row">
  <div class="column">
    <img
    src="anims/nnsrm/beforesrm_conv_cifar100_e50_l13.gif"
    style="width:100%"
    alt="beforesrm_conv_cifar100_e50_l13.gif">
    <p>Fig 1A, ConvNets, before alignment</p>
  </div>
  <div class="column">
    <img
    src="anims/nnsrm/conv_cifar100_e50_l13.gif"
    style="width:100%"
    alt="conv_cifar100_e50_l13.gif">
    <p>Fig 1B, ConvNets, after alignment</p>
  </div>
</div>



<br>
Here're the animations for 5 ResNet18 (layer 15) before (Fig 2A) vs. after alignment (Fig 2B). A more quantitaively analysis revealed that orthogonal transformations explained less variance for ResNet alignment, compared to ConvNets, suggesting high capacity models can learn representations that are more qualitatively different.
<br>

<div class="row">
  <div class="column">
    <img
    src="anims/nnsrm/beforesrm_resnet18_cifar100_e100_l55.gif"
    style="width:100%"
    alt="beforesrm_resnet18_cifar100_e100_l55.gif">
    <p>Fig 2A, ResNets, before alignment</p>
  </div>
  <div class="column">
    <img
    src="anims/nnsrm/resnet18_cifar100_e100_l55.gif"
    style="width:100%"
    alt="beforesrm_resnet18_cifar100_e100_l55.gif">
    <p>Fig 2B, ResNets, after alignment</p>
  </div>
</div>

<img vspace=20>

<br>
<b>References:</b>
<br>
<br>
[1]
Shared representational geometry across neural networks.
<br>
Lu, Q., Chen, P. H., Pillow, J. W., Ramadge, P. J., Norman, K. A., & Hasson, U.
<br>
Workshop on Integration of Deep Learning Theories, NeurIPS 2018.
<br>
<a href="https://qihongl.github.io/docs/NIPS18_poster_NNSRM.pdf">poster</a>,
<a href="https://arxiv.org/abs/1811.11684">paper</a>,
<a href="https://github.com/qihongl/nnsrm-neurips18">code</a>,
<a href="https://colab.research.google.com/github/qihongl/demo-nnalign/blob/master/demo-nnalign.ipynb">tutorial on google colab</a>, 
<a href="https://qihongl.github.io/nnsrm-NeurIPS18.html">some animations</a>

<br>
<br>
[2]
SRM is implemented in <a href="http://brainiak.org/">BrainIAK</a>
<br>
Chen, P.-H., Chen, J., Yeshurun, Y., Hasson, U., Haxby, J., & Ramadge, P. J. (2015). A Reduced-Dimension fMRI Shared Response Model. In Advances in Neural Information Processing Systems 28 (pp. 460–468).


<br>
<br>
[3]
A huge thanks to <a href="https://github.com/ContextLab/hypertools">hypertools</a>,
the package I used to make these animations.
<br>
Heusser, A. C., Ziman, K., Owen, L. L. W., & Manning, J. R. (2018). HyperTools: a Python Toolbox for Gaining Geometric Insights into High-Dimensional Data. Journal of Machine Learning Research: JMLR, 18(152), 1–6.

</section>


</div>
<script src="javascripts/scale.fix.js"></script>

</body>

</html>
